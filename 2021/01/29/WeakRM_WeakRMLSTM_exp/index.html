<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Welcome to my personal blogs">
    <meta name="author" content="Yuxuan Wu">
    
    <title>
        
            WeakRM &amp; WeakRMLSTM model explanation |
        
        Yuxuan Wu
    </title>
    <link rel="shortcut icon" href="/images/logo.svg">
    
<link rel="stylesheet" href="/css/style.css">

    
<link rel="stylesheet" href="/css/font-awesome.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"example.com","root":"/","language":"en","path":"search.xml"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":false},"style":{"primary_color":"#0066CC","avatar":"/images/avatar.svg","favicon":"/images/logo.svg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":true,"scale":true},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"Keep coding, Keep hungry."},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":true}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":false},"lazyload":{"enable":false},"version":"3.3.1"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days age","week":"%s weeks age","month":"%s months age","year":"%s years age"};
  </script>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.3.0"></head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            <a class="logo-title" href="/">
                Yuxuan Wu
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/categories"
                            >
                                CATEGORIES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/tags"
                            >
                                TAGS
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/about"
                            >
                                ABOUT
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/categories">CATEGORIES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/tags">TAGS</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/about">ABOUT</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content normal-code-theme">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">WeakRM &amp; WeakRMLSTM model explanation</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/avatar.svg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Yuxuan Wu</span>
                        <span class="level">Lv11</span>
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i> 2021-01-29 08:07:35
    </span>
    
        <span class="article-categories article-meta-item">
            <i class="fas fa-folder"></i>
            <ul>
                
                    <li>
                        <a href="/categories/FYP/">FYP</a>
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>
            <ul>
                
                    <li>
                        <a href="/tags/tutorial/">tutorial</a>
                    </li>
                
                    <li>
                        | <a href="/tags/Multi-instance-learning/">Multi-instance learning</a>
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fas fa-file-word"></i> <span>1.3k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fas fa-clock"></i> <span>8 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i> <span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <p>This python file aims to build the weakly-supervised learning by tensorflow</p>
<p><strong>Notes related to the code</strong></p>
<ol>
<li>Tensorflow language:</li>
</ol>
<p><code>tf.transpose</code>:<a class="link"   target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/transpose" >https://www.tensorflow.org/api_docs/python/tf/transpose<i class="fas fa-external-link-alt"></i></a></p>
<p><code>perm</code>: A permutation of the dimensions of <code>a</code>. This should be a vector.</p>
<blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">x = tf.constant([[[ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">                  [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>]],</span><br><span class="line">                 [[ <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>],</span><br><span class="line">                  [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]]])</span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;*&#x27;</span>*<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">print(tf.transpose(x, perm=[<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;tf.Tensor(</span><br><span class="line">[[[ <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>]</span><br><span class="line">  [ <span class="number">4</span>  <span class="number">5</span>  <span class="number">6</span>]]</span><br><span class="line"> [[ <span class="number">7</span>  <span class="number">8</span>  <span class="number">9</span>]</span><br><span class="line">  [<span class="number">10</span> <span class="number">11</span> <span class="number">12</span>]]], shape=(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>), dtype=int32)</span><br><span class="line">****************************************************************************************************</span><br><span class="line">&gt;&gt;&gt;tf.Tensor(</span><br><span class="line">[[[ <span class="number">1</span>  <span class="number">4</span>]</span><br><span class="line">  [ <span class="number">2</span>  <span class="number">5</span>]</span><br><span class="line">  [ <span class="number">3</span>  <span class="number">6</span>]]</span><br><span class="line"> [[ <span class="number">7</span> <span class="number">10</span>]</span><br><span class="line">  [ <span class="number">8</span> <span class="number">11</span>]</span><br><span class="line">  [ <span class="number">9</span> <span class="number">12</span>]]], shape=(<span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>), dtype=int32)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ol start="2">
<li>What is global max pooling layer and what is its advantage over maxpooling layer?</li>
</ol>
</blockquote>
<blockquote>
<p>Global max pooling = ordinary max pooling layer with pool size equals to the size of the input (minus filter size + 1, to be precise). You can see that <code>MaxPooling1D</code> takes a <code>pool_length</code> argument, whereas <code>GlobalMaxPooling1D</code> does not</p>
</blockquote>
<p><strong>Links from zhihu</strong>：<a class="link"   target="_blank" rel="noopener" href="https://www.zhihu.com/question/358913301/answer/922183264" >https://www.zhihu.com/question/358913301/answer/922183264<i class="fas fa-external-link-alt"></i></a></p>
<ol start="3">
<li>Why do we need to specify whether training equals true in the call part?</li>
</ol>
<blockquote>
<p>Some neural network layers behave differently during training and inference, for example Dropout and BatchNormalization layers. For example</p>
<ul>
<li>During training, dropout will randomly drop out units and correspondingly scale up activations of the remaining units.</li>
<li>During inference, it does nothing (since you usually don’t want the randomness of dropping out units here).</li>
<li>The training argument lets the layer know which of the two “paths” it should take. If you set this incorrectly, your network might not behave as expected.</li>
</ul>
</blockquote>
<p><strong>example from keras official website</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">x = tf.constant([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>, <span class="number">5.</span>])</span><br><span class="line">x = tf.reshape(x, [<span class="number">1</span>, <span class="number">5</span>, <span class="number">1</span>])</span><br><span class="line">print(<span class="string">&#x27;tf_reshape format&#x27;</span>)</span><br><span class="line">print(x)</span><br><span class="line">max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=<span class="number">2</span>,</span><br><span class="line">                                           strides=<span class="number">1</span>, padding=<span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line">print(max_pool_1d(x))</span><br><span class="line"></span><br><span class="line">******************************</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tf_reshape <span class="built_in">format</span></span><br><span class="line">tf.Tensor(</span><br><span class="line">[[[<span class="number">1.</span>]</span><br><span class="line">  [<span class="number">2.</span>]</span><br><span class="line">  [<span class="number">3.</span>]</span><br><span class="line">  [<span class="number">4.</span>]</span><br><span class="line">  [<span class="number">5.</span>]]], shape=(<span class="number">1</span>, <span class="number">5</span>, <span class="number">1</span>), dtype=float32)</span><br><span class="line">tf.Tensor(</span><br><span class="line">[[[<span class="number">2.</span>]</span><br><span class="line">  [<span class="number">3.</span>]</span><br><span class="line">  [<span class="number">4.</span>]</span><br><span class="line">  [<span class="number">5.</span>]]], shape=(<span class="number">1</span>, <span class="number">4</span>, <span class="number">1</span>), dtype=float32)</span><br></pre></td></tr></table></figure>
<p>**gloabl max pooling **</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = tf.constant([[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>], [<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>], [<span class="number">7.</span>, <span class="number">8.</span>, <span class="number">9.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = tf.reshape(x, [<span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">&lt;tf.Tensor: shape=(<span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>), dtype=float32, numpy=</span><br><span class="line">array([[[<span class="number">1.</span>], [<span class="number">2.</span>], [<span class="number">3.</span>]],</span><br><span class="line">       [[<span class="number">4.</span>], [<span class="number">5.</span>], [<span class="number">6.</span>]],</span><br><span class="line">       [[<span class="number">7.</span>], [<span class="number">8.</span>], [<span class="number">9.</span>]]], dtype=float32)&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>max_pool_1d = tf.keras.layers.GlobalMaxPooling1D()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>max_pool_1d(x)</span><br><span class="line">&lt;tf.Tensor: shape=(<span class="number">3</span>, <span class="number">1</span>), dtype=float32, numpy=</span><br><span class="line">array([[<span class="number">3.</span>],</span><br><span class="line">       [<span class="number">6.</span>],</span><br><span class="line">       [<span class="number">9.</span>], dtype=float32&gt;</span><br></pre></td></tr></table></figure>


<p><strong>difference between conv1d and conv2d</strong></p>
<p>In 1D CNN, kernel moves in 1 direction. Input and output data of 1D CNN is 2 dimensional. Mostly used on Time-Series data.</p>
<p>In 2D CNN, kernel moves in 2 directions. Input and output data of 2D CNN is 3 dimensional. Mostly used on Image data.</p>
<blockquote>
<p>Therefore you have to carefully chose the filter size. For instance, if you chose a Conv2D with a filter size (4,2), it will produce the same results as a Conv1D with size (4) as it will operate fully on the second axis of data.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.regularizers <span class="keyword">import</span> l2</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.activations <span class="keyword">import</span> sigmoid</span><br><span class="line"></span><br><span class="line">tfk = tf.keras</span><br><span class="line">tfkl = tf.keras.layers</span><br><span class="line">tfkc = tf.keras.callbacks</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WeakRM</span>(<span class="params">tf.keras.Model</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(WeakRM, self).__init__()</span><br><span class="line">        <span class="comment"># 1D batch = 6, 保证每一条instance的参数都是由CNN来提取的</span></span><br><span class="line">        self.conv1 = tfkl.Conv1D(<span class="number">32</span>, <span class="number">15</span>, padding=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.conv2 = tfkl.Conv1D(<span class="number">16</span>, <span class="number">5</span>, padding=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                 kernel_regularizer=l2(<span class="number">0.005</span>))</span><br><span class="line">        self.dropout = tfkl.Dropout(<span class="number">0.2</span>)</span><br><span class="line">        self.pool1 = tfkl.MaxPool1D(pool_size=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.att_v = tfkl.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;tanh&#x27;</span>)</span><br><span class="line">        self.att_u = tfkl.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.attention_weights = tfkl.Dense(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.classifier = tfkl.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs, training=<span class="literal">True</span>, mask=<span class="literal">None</span></span>):</span></span><br><span class="line">        input_bag = tf.squeeze(inputs, axis=<span class="number">0</span>)</span><br><span class="line">        <span class="comment">## squeeze function is to remove all the shape equal 1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">## so we could use the convolutional</span></span><br><span class="line">        inst_conv1 = self.conv1(input_bag)</span><br><span class="line">        inst_pool1 = self.pool1(inst_conv1)</span><br><span class="line">        inst_pool1 = self.dropout(inst_pool1, training=training)</span><br><span class="line"></span><br><span class="line">        inst_conv2 = self.conv2(inst_pool1)</span><br><span class="line"></span><br><span class="line">        inst_features = tfkl.Flatten()(inst_conv2)</span><br><span class="line"></span><br><span class="line">        attention_vmatrix = self.att_v(inst_features)</span><br><span class="line">        attention_umatrix = self.att_u(inst_features)</span><br><span class="line"></span><br><span class="line">        gated_attention = self.attention_weights(attention_vmatrix * attention_umatrix)</span><br><span class="line"></span><br><span class="line">        gated_attention = tf.transpose(gated_attention, perm=[<span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">        <span class="comment"># perm is simply a transpose function, especially useful in high dimension</span></span><br><span class="line">        </span><br><span class="line">        gated_attention = tfkl.Softmax()(gated_attention)</span><br><span class="line"></span><br><span class="line">        bag_features = tf.matmul(gated_attention, inst_features)</span><br><span class="line"></span><br><span class="line">        bag_probability = self.classifier(bag_features)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> bag_probability, gated_attention</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>The first model was built by Deep CNN and the incorporation of gated attention mechanisms. </p>
<p>The model returns both bag probability and gated attention value</p>
<p>$$<br>a_k = \frac{exp(w^T(tanh(Vh_k{^T})\otimes sigm(Uh_k^T)))}{\sum_{j=1}^Kexp(w^T(tanh(Vh_j^T)\otimes sigm(Uh_j^T)))}<br>$$</p>
<p>$$<br>z = \sum_{k=1}^{K}a_kh_k<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">      </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WeakRMLSTM</span>(<span class="params">tf.keras.Model</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(WeakRMLSTM, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.conv1 = tf.keras.layers.Conv2D(<span class="number">16</span>, (<span class="number">1</span>, <span class="number">15</span>), padding=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        <span class="comment"># self.conv1 = tfkl.Conv1D(32, 15, padding=&#x27;same&#x27;, activation=&#x27;relu&#x27;)</span></span><br><span class="line">        <span class="comment"># self.conv2 = tfkl.Conv1D(16, 5, padding=&#x27;same&#x27;, activation=&#x27;relu&#x27;,</span></span><br><span class="line">        <span class="comment">#                          kernel_regularizer=l2(0.005))</span></span><br><span class="line">        self.lstm = tf.keras.layers.TimeDistributed(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">16</span>)))</span><br><span class="line">        self.dropout = tfkl.Dropout(<span class="number">0.2</span>)</span><br><span class="line">        self.pool1 = tfkl.MaxPool2D(pool_size=(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">        self.att_v = tfkl.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;tanh&#x27;</span>)</span><br><span class="line">        self.att_u = tfkl.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.attention_weights = tfkl.Dense(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.classifier = tfkl.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs, training=<span class="literal">True</span>, mask=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># input_bag = tf.squeeze(inputs, axis=0)</span></span><br><span class="line">        input_bag = inputs</span><br><span class="line">        inst_conv1 = self.conv1(input_bag)</span><br><span class="line">        inst_pool1 = self.pool1(inst_conv1)</span><br><span class="line">        <span class="keyword">if</span> training:</span><br><span class="line">            inst_pool1 = self.dropout(inst_pool1, training=training)</span><br><span class="line"></span><br><span class="line">        inst_conv2 = self.lstm(inst_pool1)</span><br><span class="line"></span><br><span class="line">        inst_features = tf.squeeze(inst_conv2, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        attention_vmatrix = self.att_v(inst_features)</span><br><span class="line">        attention_umatrix = self.att_u(inst_features)</span><br><span class="line"></span><br><span class="line">        gated_attention = self.attention_weights(attention_vmatrix * attention_umatrix)</span><br><span class="line"></span><br><span class="line">        gated_attention = tf.transpose(gated_attention, perm=[<span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">        gated_attention = tfkl.Softmax()(gated_attention)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># tf.stop_gradient(gated_attention)</span></span><br><span class="line"></span><br><span class="line">        bag_features = tf.matmul(gated_attention, inst_features)</span><br><span class="line"></span><br><span class="line">        bag_probability = self.classifier(bag_features)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> bag_probability, gated_attention</span><br></pre></td></tr></table></figure>


<p>The difference is that this model add a new lstm network</p>
<p>As I mentioned before, if you chose a Conv2D with a filter size (4,2), it will produce the same results as a Conv1D with size (4) as it will operate fully on the second axis of data. Therefore, you could change the previous LSTM code into Conv1D format. Here you need to pay attention to the lstm layer, since the input of <strong>tf.keras.layers.TimeDistributed</strong> should be at least 3D. If you still retain this in the LSTM layer, you could obtain an error.</p>
<p>From CSDN: </p>
<p><a class="link"   target="_blank" rel="noopener" href="https://stackoverflow.com/questions/47305618/what-is-the-role-of-timedistributed-layer-in-keras" >What is the role of TimeDistributed layer in Keras?<i class="fas fa-external-link-alt"></i></a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WeakRMLSTM</span>(<span class="params">tf.keras.Model</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(WeakRMLSTM, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># self.conv1 = tf.keras.layers.Conv2D(16, (1, 15), padding=&#x27;same&#x27;, activation=&#x27;relu&#x27;)</span></span><br><span class="line">        self.conv1 = tfkl.Conv1D(<span class="number">16</span>, <span class="number">15</span>, padding=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                 kernel_regularizer=l2(<span class="number">0.005</span>))</span><br><span class="line">        self.lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">16</span>))</span><br><span class="line">        self.dropout = tfkl.Dropout(<span class="number">0.2</span>)</span><br><span class="line">        self.pool1 = tfkl.MaxPool1D(pool_size=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.att_v = tfkl.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;tanh&#x27;</span>)</span><br><span class="line">        self.att_u = tfkl.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.attention_weights = tfkl.Dense(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.classifier = tfkl.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs, training=<span class="literal">True</span>, mask=<span class="literal">None</span></span>):</span></span><br><span class="line">        input_bag = tf.squeeze(inputs, axis=<span class="number">0</span>)</span><br><span class="line">            <span class="comment"># input_bag = inputs</span></span><br><span class="line">        inst_conv1 = self.conv1(input_bag)</span><br><span class="line">        inst_pool1 = self.pool1(inst_conv1)</span><br><span class="line">        inst_pool1 = self.dropout(inst_pool1, training=training)</span><br><span class="line"></span><br><span class="line">        inst_conv2 = self.lstm(inst_pool1)</span><br><span class="line"></span><br><span class="line">        inst_features = tfkl.Flatten()(inst_conv2)</span><br><span class="line">        <span class="comment"># inst_features = tfkl.Flatten()(inst_conv1)</span></span><br><span class="line"></span><br><span class="line">        attention_vmatrix = self.att_v(inst_features)</span><br><span class="line">        attention_umatrix = self.att_u(inst_features)</span><br><span class="line"></span><br><span class="line">        gated_attention = self.attention_weights(attention_vmatrix * attention_umatrix)</span><br><span class="line"></span><br><span class="line">        gated_attention = tf.transpose(gated_attention, perm=[<span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">        gated_attention = tfkl.Softmax()(gated_attention)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># tf.stop_gradient(gated_attention)</span></span><br><span class="line"></span><br><span class="line">        bag_features = tf.matmul(gated_attention, inst_features)</span><br><span class="line"></span><br><span class="line">        bag_probability = self.classifier(bag_features)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> bag_probability, gated_attention</span><br></pre></td></tr></table></figure>


<p>A brief outline of how tf.keras.model works</p>
<p><img src="https://tf.wiki/_images/model.png" alt="img"></p>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul>
        <li>Post title：WeakRM &amp; WeakRMLSTM model explanation</li>
        <li>Post author：Yuxuan Wu</li>
        <li>Create time：2021-01-29 08:07:35</li>
        <li>
            Post link：yuxuanwu17.github.io2021/01/29/WeakRM_WeakRMLSTM_exp/
        </li>
        <li>
            Copyright Notice：All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

            </div>
        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/2021/01/29/performance_exp/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">performance explanation</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/2021/01/28/token2npy/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">token2npy explanation</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span> -
            
            2021 <i class="fas fa-heart icon-animate"></i> <a href="/">Yuxuan Wu</a>
        </div>
        
            <script async  src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        Visitor Count <span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
                    <span id="busuanzi_container_site_pv">
                        Totalview <span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a> | Theme <a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.3.1</a>
        </div>
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>



    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-copy.js"></script>





<div class="post-scripts">
    
        
<script src="/js/left-side-toggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/toc.js"></script>

    
</div>



</body>
</html>
